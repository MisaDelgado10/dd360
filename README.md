# dd360

<a target="_blank" href="https://cookiecutter-data-science.drivendata.org/">
    <img src="https://img.shields.io/badge/CCDS-Project%20template-328F97?logo=cookiecutter" />
</a>

## ğŸ  Reto de Data Science â€“ Comparables Inmobiliarios en CuauhtÃ©moc, CDMX

ğŸ“Œ Objetivo

Desarrollar una funciÃ³n get_comparables() que, a partir de hasta 7 inputs simples, devuelva una lista con los url_ad de las 5 propiedades mÃ¡s similares (comparables) dentro del dataset proporcionado.
Se busca un enfoque claro, escalable y explicable sobre quÃ© significa que las propiedades sean comparables.


## Contenido del repositorio

```
â”œâ”€â”€ data
â”‚   â”œâ”€â”€ external       <- Data from third party sources.
â”‚   â”œâ”€â”€ interim        <- Intermediate data that has been transformed.
â”‚   â”œâ”€â”€ processed      <- The final, canonical data sets for modeling.
â”‚   â””â”€â”€ raw            <- The original, immutable data dump.
â”‚
â””â”€â”€ dd360   <- Source code for use in this project.
    â”‚
    â”œâ”€â”€ __init__.py             <- Makes dd360 a Python module
    â”‚
    â”œâ”€â”€ compare.py              <- has different functions to calculate similar buildings
    â”‚
    â”œâ”€â”€ config.py               <- Store useful variables and configuration
    â”‚
    â”œâ”€â”€ experiments.py          <- This works as a testing file to produce an average similarity score of the functions in compare.py
    â”‚
    â”œâ”€â”€ extract.py              <- This extracts data stored in the data/ folder
    â”‚
    â”œâ”€â”€ feature_importance.py   <- It runs different experiments to see the most important variables (correlation, PCA, etc)
    â”‚
    â”œâ”€â”€ features.py             <- Code to create new features for the similarity experiment
    â”‚
    â”œâ”€â”€ transform.py             <- Code to imput missing values, trate outliers and standardize feature values
    â”‚
    â”œâ”€â”€ modeling
    â”‚   â”œâ”€â”€ __init__.py
    â”‚   â”œâ”€â”€ predict.py          <- Code to run model inference with trained models (not used in this stage)
    â””â”€â”€ â”œâ”€â”€ train.py            <- Code to train models (not used in this stage)
â”‚
â”œâ”€â”€ docs               <- A default mkdocs project; see www.mkdocs.org for details
â”‚
â”œâ”€â”€ models             <- Trained and serialized models, model predictions, or model summaries (not used in this stage)
â”‚
â”œâ”€â”€ notebooks          <- Jupyter notebooks. Naming convention is a number (for ordering),
â”‚                         `1.EDA.ipynb`.
â”œâ”€â”€ references         <- Data dictionaries, manuals, and all other explanatory materials.
â”‚
â”œâ”€â”€ reports            <- Generated analysis as HTML, PDF, LaTeX, etc.
â”‚   â””â”€â”€ figures        <- Generated graphics and figures to be used in reporting
â”‚
â”œâ”€â”€ Makefile           <- Makefile with convenience commands like `make data` or `make train`
â”‚
â”œâ”€â”€ pyproject.toml     <- Project configuration file with package metadata for
â”‚                         dd360 and configuration for tools like black
â”œâ”€â”€ requirements.txt   <- The requirements file for reproducing the analysis environment, e.g.
â”‚                         generated with `pip install -r requirements.txt`
â”œâ”€â”€ setup.cfg          <- Configuration file for flake8

```

--------

### ğŸ§  Â¿CÃ³mo definÃ­ â€œcomparabilidadâ€?
Una propiedad es comparable si:

a) Se encuentra en la misma colonia.
b) Es del mismo tipo de propiedad (casa o departamento).
c) Tiene caracterÃ­sticas numÃ©ricas similares (precio por metro cuadrado, # dormitorios, # baÃ±os,  antigÃ¼edad del inmueble y si tiene amenidades como gym o jardÃ­n).

Se usÃ³ un enfoque mixto:

Filtrado categÃ³rico por colonia y tipo y Distancia euclidiana entre variables numÃ©ricas normalizadas.

### ğŸ“Š AnÃ¡lisis Exploratorio
Se identificÃ³ que el precio varÃ­a significativamente entre colonias.

El tipo de propiedad tiene fuerte relaciÃ³n con otras variables (casas tienen mÃ¡s superficie, mÃ¡s jardÃ­n).

Variables como conservation_status, construction_surface y price presentan correlaciones importantes.

Muchas columnas tienen valores faltantes y la forma en cÃ³mo se van a imputar es llenÃ¡ndolas con la mediana de la colonia a la que pertenece el edificio.
Muchas columnas tienen outliers tambien, por lo que se les harÃ¡ un tratamiento para normalizarlas o limitar sus rangos.

### ğŸ› ï¸ Transformaciones / Feature Engineering

1. Se imputaron variables con la media
2. Se hizo tratamiento de outliers
3. Se crearon nuevas features con one hot encoding y otras simples como ratios i.e. price per m2

### âš—ï¸ Fase de ExperimentaciÃ³n
Se probaron y compararon distintos enfoques para definir la similitud:

* get_similars_euclidean_standard: Distancia Euclidiana con Escalado Z-score

* get_similars_euclidean_minmax: Distancia Euclidiana con Escalado MinMax

* get_similars_hierarchical: Filtra por colonia y tipo de inmueble + Distancia Euclidiana con Escalado MinMax

* get_similars_combined_geo: Filtra por colonia y tipo de inmueble + Distancia Euclidiana y Geodesica (usando lat y lng) con Escalado MinMax

Se graficaron las mÃ©tricas y se eligiÃ³ el modelo con mejor score visual y lÃ³gico.

### ğŸ¤– Algoritmo Final (get_similars_combined_geo)

1. Filtra por neighborhood y property_type.

2. Aplica escalado a variables seleccionadas.

3. Calcula la distancia euclidiana.

4. Ordena por menor distancia y devuelve las 5 mÃ¡s cercanas.

(Ver implementaciÃ³n completa en dd360_project/dd360/compare.py)

### ğŸ“‰ Limitaciones y mejoras posibles
1. Actualmente se hicieron un par de experimentos con distancias euclidianas pero podrÃ­a valer la pena probar con otros tipos de modelos mÃ¡s fancies
2. Se podrÃ­an evaluar otros mÃ©todos para checar la importancia de las variables y su impacto
3. Hacer un preprocesamiento mÃ¡s robusto como manejo de valores faltantes y outliers
4. Hacer un pipeline que automatice todo end to end, desde la extracciÃ³n de datos hasta el cÃ¡lculo de las 5 propiedades similares
5. Hacer pruebas unitarias

### ğŸ§ª Â¿QuÃ© podrÃ­a escalar mal?
1. Si el dataset crece mucho en tamaÃ±o o en cantidad de features, escalar todos los datos en memoria puede ser lento o consumir mucha RAM.
2. MÃ©todos como distancia euclidiana o jerÃ¡rquica sin optimizaciones pueden ser muy lentos para datasets grandes.
3. Si muchas propiedades tienen valores faltantes, la funciÃ³n puede tardar mÃ¡s o arrojar resultados poco fiables.
4. A mayor nÃºmero de features para calcular la distancia, mayor serÃ¡ el costo computacional para cada comparaciÃ³n.


### ğŸ§­ Conclusiones y recomendaciones
Este enfoque permite comparar propiedades de forma automÃ¡tica y rÃ¡pida, ya que antes de calcular similitud se filtra por colonia y tipo de propiedad lo que eficientiza de manera increÃ­ble el calculo de las propiedades mÃ¡s similares. TambiÃ©n, la estructura del proyecto es funcional y modular, lo que podrÃ­a fÃ¡cilmente permitir hacer mejores y pruebas.

Como recomendaciÃ³n:
1. Optimizar el cÃ¡lculo de propiedades similares, talvez con estructuras de bÃºsqueda eficientes (KDTree, BallTree).
2. Validar y limpiar mejor los datos.
3. Ampliar el anÃ¡lisis con tÃ©cnicas modernas
4. Considerar integraciÃ³n en un entorno escalable (nube)

### BONUS

Se hizo un dashboard en streamlit para obtener las 5 propiedades mÃ¡s similares en funciÃ³n de 7 features. Puedes correr el proyecto como se indica abajo o puedes ver una prueba de cÃ³mo funcciona en reports/figures/webapp_*.jpg

# â–¶ï¸ CÃ³mo instalar y correr el proyecto
```
## Clona el repositorio
1. git clone https://github.com/tu_usuario/cuauhtemoc-comparables.git

## Crea un ambiente de conda con python 3.9
2. cd dd360_project
3. conda create -n dd360 python=3.9
4. conda activate dd360

## Instala las dependencias
5. pip install poetry
6. pip install pre-commit
7. pre-commit install
8. pip install -r requirements.txt

## Lanza la app (dashboard)
9. streamlit run webapp/app.py
```
